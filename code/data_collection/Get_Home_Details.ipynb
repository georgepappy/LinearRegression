{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0912df8d",
   "metadata": {},
   "source": [
    "## This notebook visits and scrapes a list of home details urls previously collected by scraping target home search results pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e557cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests, bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import time, random\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ff31a",
   "metadata": {},
   "source": [
    "# 1) Use Previously Grabbed URL List to Get Home Details from website: \n",
    "\n",
    "### Single Family Homes that have recently sold in the City of Los Angeles\n",
    "\n",
    "#### (Note: Due to the website detecting & halting automated/repetitive activity, this should be done piecemeal - no more than 100 at a time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875d44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Update the User-Agent per \n",
    "#     this StackOverflow post: https://stackoverflow.com/questions/38489386/python-requests-403-forbidden\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36',\n",
    "           'Accept-Encoding': 'gzip, deflate, br', \n",
    "           'Accept': '*/*', \n",
    "           'Connection': 'keep-alive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56abc6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = '<website homepage url here>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad132b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [el[0] for el in pd.read_csv('<text filename with specific home urls to visit>', header=None).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f40115",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n, url in enumerate(urls):\n",
    "    url = url_base + url\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Delay (make absolutely sure response was received)\n",
    "    time.sleep(5)\n",
    "    status = response.status_code\n",
    "    if status == 200:\n",
    "        print('Success! Got page {}'.format(n))\n",
    "        page = response.text\n",
    "        soup = bs(page)\n",
    "        \n",
    "        # Get the variables we need; start with zipcode, sold_price, beds, baths & hm_sqft \n",
    "        try:\n",
    "            stats = [val.text for val in soup.find(id='content').find_all('div', {'class': 'top-stats'})]\n",
    "            \n",
    "            if 'Sold Price' in [val.text for val in soup.find(id='content').find_all('div', {'class': 'top-stats'})][0]:\n",
    "                stats = stats[0].replace('CA',' ').replace('$',' ').replace('Sold Price',' ') \\\n",
    "                                .replace('Beds',' ').replace('Baths',' ').replace('Sq Ft',' ').replace(',','').split()[-5:]\n",
    "                zipcode, sold_price, beds, baths, hm_sqft = stats[0], stats[1], stats[2], stats[3], stats[4]\n",
    "            else:\n",
    "                stats = stats[0].replace('CA',' ').replace('$',' ').replace('Redfin Estimate',' ') \\\n",
    "                                .replace('Beds',' ').replace('Baths',' ').replace('Sq Ft',' ').replace(',','').split()[-5:]\n",
    "                zipcode, sold_price, beds, baths, hm_sqft = stats[0], np.nan, stats[2], stats[3], stats[4]\n",
    "        except:\n",
    "            zipcode = sold_price = beds = baths = hm_sqft = np.nan\n",
    "            \n",
    "        # Next get stories, yr_built and lot_size\n",
    "        try:\n",
    "            stories = soup.find(text='Stories').next.text\n",
    "        except:\n",
    "            stories = np.nan\n",
    "        try:\n",
    "            yr_built = soup.find(text='Year Built').next.text\n",
    "        except:\n",
    "            yr_built = np.nan\n",
    "        try:\n",
    "            lot_size = soup.find(text='Lot Size').next.text\n",
    "        except:\n",
    "            lot_size = np.nan\n",
    "            \n",
    "        # Now get garage & pool\n",
    "        try:\n",
    "            amenities = [el.text.lower() for el in soup.find('div', {'class': 'amenities-container'})]\n",
    "        except:\n",
    "            amenities = []\n",
    "        garage = sum(['garage' in el for el in amenities]) > 0\n",
    "        pool = sum(['pool' in el for el in amenities]) > 0\n",
    "        \n",
    "        # Finally, get schools\n",
    "        try:\n",
    "            schools = soup.find(text='GreatSchools Rating').next.text.split('/')\n",
    "            schools = np.mean([int(el[-1:]) for el in schools if el[-1:].isnumeric()])\n",
    "        except:\n",
    "            schools = np.nan\n",
    "        \n",
    "        # Save this row of data to csv  \n",
    "        tup = (sold_price, beds, baths, hm_sqft, lot_size, yr_built, zipcode, pool, garage, stories, schools)\n",
    "        with open('home_details_1.csv', 'a') as f:\n",
    "            writer = csv.writer(f , lineterminator='\\n')\n",
    "            writer.writerow(tup)        \n",
    "    \n",
    "    else:\n",
    "        print('Fail! Received status code {} for page {}'.format(status, n))\n",
    "    \n",
    "    # Delay some more to linger on the page before moving on (35 +/- 5 seconds)\n",
    "    time.sleep(20 + 7*(random.random() - 0.5))\n",
    "    \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c5298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
